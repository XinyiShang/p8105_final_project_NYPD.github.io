---
title: "General Crime Data"
output: 
  html_document
---

------------------------------------------------------------------------

```{r defaults, echo = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(dplyr)
library(lubridate)
library(htmltools)
library(viridis)
library(shiny)
library(plotly)

# set knitr defaults
knitr::opts_chunk$set(
    echo      = TRUE
  , message   = FALSE
  , warning   = FALSE
  , fig.align = "center"
)

# set theme defaults
theme_set(
  theme_bw() +
  theme(
    legend.position = "bottom"
    , plot.title    = element_text(hjust = 0.5)
    , plot.subtitle = element_text(hjust = 0.5)    
    , plot.caption  = element_text(hjust = 0.0)
  )
)

# set color scale defaults
options(
    ggplot2.continuous.colour = "viridis"
  , ggplot2.continuous.fill   = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete   = scale_fill_viridis_d
```

```{r load data}
df_nypd = read_csv("https://www.dropbox.com/scl/fi/kf2zk4t1onxzm2vo3lpkq/NYPD_Complaint_Data_Historic.csv?rlkey=ly36vi9v66sno80eir6rohlwn&dl=1", na = "(null)") |>
  janitor::clean_names()
```

```{r}
# Compare ky_cd vs pd_cd
length(unique(df_nypd |> pull(ky_cd)))
length(unique(df_nypd |> pull(pd_cd)))
sum(is.na(df_nypd$ky_cd))
sum(is.na(df_nypd$pd_cd))
```
Decide to use ky_cd as crime classification code to avoid excessive complication and missing values.


```{r}
mapping <- df_nypd |> 
  mutate(ofns_desc = ifelse(is.na(ofns_desc), pd_desc, ofns_desc)) |> 
  distinct(ky_cd, ofns_desc) 
```

Since there are `r n(unique(ky_cd)` crime categories, which is still quite a lot to do interpretable visualizations, I decided to only include crime categories that make up 80% of all the crime data to capture most frequent crime categories.

## Temporal Patterns
```{r}

# Step 1: Group, count, and sort
df_summary <- df_nypd %>%
  group_by(ky_cd) %>%
  summarise(n = n()) %>%
  arrange(desc(n))

# Calculate total number of observations
total_n <- sum(df_summary$n)

# Determine a cutoff, for example, 80% of the total
cutoff <- total_n * 0.80

# Calculate the cumulative sum and find out how many top categories 
# make up for at least 80% of the data
df_summary <- df_summary |> 
  mutate(cumulative_n = cumsum(n))

position <- which.max(df_summary$cumulative_n >= cutoff)
# Select the top categories up to this position
df_summary <- df_summary[1:position, ] |> 
  left_join(mapping, by="ky_cd")
# Optional: Viewing the result
print(df_summary)
```
The most frequent 10 crime categories constitute at least 80% of all the crimes in NYC.

Noteworthy, ky_cd `361` consists 2 different description, which could be combined, while `126` consists 2 that need further discussion.


```{r}
df_crime_patterns <- df_nypd %>%
  filter(ky_cd %in% df_summary$ky_cd)
```

